{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzhKV2nQkO8x"
   },
   "source": [
    "# üéì Aula 1: Introdu√ß√£o aos principais conceitos de modelos preditivos.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã √çndice\n",
    "\n",
    "1. [Problema de Classifica√ß√£o](#classifica√ß√£o)\n",
    "   - Gera√ß√£o de Dados Sint√©ticos\n",
    "   - Visualiza√ß√£o e Explora√ß√£o\n",
    "   - Treino e Avalia√ß√£o de Modelo KNN\n",
    "   - An√°lise de Overfitting\n",
    "2. [Problema de Regress√£o](#regress√£o)\n",
    "   - Carregamento e Explora√ß√£o de Dados\n",
    "   - Pr√©-processamento (Normaliza√ß√£o e One-Hot Encoding)\n",
    "   - Treino e Avalia√ß√£o de Regress√£o Linear\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos de Aprendizagem\n",
    "\n",
    "Ao completares este notebook ser√°s capaz de:\n",
    "\n",
    "1. **Compreender** a diferen√ßa entre problemas de classifica√ß√£o e regress√£o\n",
    "2. **Aplicar** treinar o teu primeiro modelo de Machine Learning\n",
    "3. **Interpretar** m√©tricas de avalia√ß√£o (matriz de confus√£o, precision, recall, MAE)\n",
    "4. **Reconhecer** sinais de overfitting comparando performance em treino vs. teste\n",
    "5. **Praticar** t√©cnicas de pr√©-processamento: normaliza√ß√£o e one-hot encoding\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Pr√©-requisitos\n",
    "\n",
    "Antes de come√ßar, certifica-te de que voc√™:\n",
    "- Tens conhecimento b√°sico de Python e pandas\n",
    "- Entendes conceitos b√°sicos de estat√≠stica (m√©dia, desvio padr√£o)\n",
    "- Est√°s familiarizado com o ambiente Google Colab\n",
    "- Compreendes a diferen√ßa entre vari√°veis categ√≥ricas e num√©ricas\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ Configura√ß√£o Inicial\n",
    "\n",
    "Executa a c√©lula abaixo para garantir que todas as bibliotecas necess√°rias est√£o dispon√≠veis. Se alguma importa√ß√£o falhar, use `!pip install nome_da_biblioteca` para instalar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"classifica√ß√£o\"></a> üìä Problema de Classifica√ß√£o\n",
    "\n",
    "## Parte 1: Gera√ß√£o e Visualiza√ß√£o de Dados Sint√©ticos\n",
    "\n",
    "### üéì Conceito: Dados Sint√©ticos para Aprendizagem\n",
    "\n",
    "Em machine learning, muitas vezes come√ßamos com **dados sint√©ticos** (gerados artificialmente) porque:\n",
    "- S√£o simples e f√°ceis de visualizar\n",
    "- Permitem focar nos conceitos sem distra√ß√µes de dados reais complexos\n",
    "- Garantem que sabemos a \"verdade\" sobre os dados (ground truth)\n",
    "\n",
    "> **Key Insight:** Dados sint√©ticos s√£o uma ferramenta pedag√≥gica poderosa. Eles permitem-nos entender como os algoritmos funcionam antes de lidar com a complexidade e ru√≠do dos dados reais.\n",
    "\n",
    "### üìù O que vamos fazer nesta c√©lula:\n",
    "\n",
    "1. **Importar bibliotecas** essenciais para machine learning e visualiza√ß√£o\n",
    "2. **Gerar dados sint√©ticos** usando `make_blobs` do scikit-learn\n",
    "3. **Visualizar os dados** num gr√°fico de dispers√£o 2D\n",
    "\n",
    "### ‚ö†Ô∏è Aten√ß√£o Especial:\n",
    "\n",
    "- `make_blobs` cria \"nuvens\" de pontos (clusters) separados\n",
    "- Cada ponto pertence a uma classe (0 ou 1)\n",
    "- `random_state=0` garante resultados reproduz√≠veis\n",
    "\n",
    "### ü§î Antes de executares, pensa:\n",
    "\n",
    "- Quantas classes esperas ver no gr√°fico?\n",
    "- Como √© que os pontos das diferentes classes devem estar distribu√≠dos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "F7PWxvPukLpy",
    "outputId": "502eb6c8-b26a-4901-d658-7c83b6e95985"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "# ============================================================================\n",
    "# sklearn: Biblioteca principal para machine learning em Python\n",
    "#   - make_blobs: Gera dados sint√©ticos em formato de clusters\n",
    "# numpy: Opera√ß√µes num√©ricas eficientes (arrays multidimensionais)\n",
    "# matplotlib: Visualiza√ß√£o de dados (gr√°ficos e plots)\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "# ============================================================================\n",
    "# GERA√á√ÉO DE DADOS SINT√âTICOS\n",
    "# ============================================================================\n",
    "# make_blobs cria pontos agrupados em \"nuvens\" (blobs)\n",
    "# Par√¢metros importantes:\n",
    "#   - centers=2: Cria 2 grupos distintos (2 classes)\n",
    "#   - cluster_std=2: Desvio padr√£o dos clusters (quanto maior, mais espalhados)\n",
    "#   - n_samples=50: Total de pontos gerados (25 por classe)\n",
    "#   - random_state=0: Semente aleat√≥ria para reproducibilidade\n",
    "#\n",
    "# Retorna:\n",
    "#   - X: Array (50, 2) com as coordenadas dos pontos [vari√°veis explicativas]\n",
    "#   - y: Array (50,) com as classes (0 ou 1) [vari√°vel target/objetivo]\n",
    "X, y = make_blobs(centers=2, cluster_std=2, random_state=0, n_samples=50)\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZA√á√ÉO DOS DADOS\n",
    "# ============================================================================\n",
    "# Criar figura para o gr√°fico\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.gca().set_aspect(\"equal\")  # Eixos com mesma escala (importante para dist√¢ncias)\n",
    "\n",
    "# scatter: Gr√°fico de dispers√£o\n",
    "#   - X[:, 0]: Primeira coordenada (eixo x)\n",
    "#   - X[:, 1]: Segunda coordenada (eixo y)\n",
    "#   - c=y: Cores baseadas nas classes (0=azul, 1=laranja por padr√£o)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=100, alpha=0.6, edgecolors='black', linewidth=1.5)\n",
    "plt.xlabel('Caracter√≠stica 1', fontsize=12)\n",
    "plt.ylabel('Caracter√≠stica 2', fontsize=12)\n",
    "plt.title('Distribui√ß√£o dos Dados Sint√©ticos (2 Classes)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(label='Classe')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìä OBSERVA√á√ÉO: Nota como os pontos formam dois grupos distintos.\n",
    "#    Isso facilita a tarefa de classifica√ß√£o visto que um algoritmo deve conseguir\n",
    "#    separar essas duas classes com relativa facilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Checkpoint: Explorando a Estrutura dos Dados\n",
    "\n",
    "Agora vamos **inspecionar** a estrutura dos dados que acabamos de gerar. Isso √© uma pr√°tica essencial em qualquer projeto de ML!\n",
    "\n",
    "> **Key Insight:** Verifica sempre a forma (shape) dos dados antes de os processares. Isso evita erros comuns de dimens√µes incompat√≠veis.\n",
    "\n",
    "**O que esperamos ver:**\n",
    "- `X.shape` deve retornar `(50, 2)` ‚Üí 50 amostras, 2 caracter√≠sticas\n",
    "- `y.shape` deve retornar `(50,)` ‚Üí 50 labels correspondentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1iW1WlFnJRC",
    "outputId": "989cd741-ba3d-42cd-ccbf-87e109141b3d"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFICA√á√ÉO DA ESTRUTURA DOS DADOS\n",
    "# ============================================================================\n",
    "# .shape retorna (n√∫mero_de_linhas, n√∫mero_de_colunas)\n",
    "# Para X: esperamos (50, 2) ‚Üí 50 amostras, 2 caracter√≠sticas\n",
    "print(\"Forma da matriz X (vari√°veis explicativas):\")\n",
    "print(f\"  X.shape = {X.shape}\")\n",
    "print(f\"  ‚Üí {X.shape[0]} amostras, {X.shape[1]} caracter√≠sticas\\n\")\n",
    "\n",
    "print(\"Forma do vetor y (vari√°vel target):\")\n",
    "print(f\"  y.shape = {y.shape}\")\n",
    "print(f\"  ‚Üí {y.shape[0]} labels\\n\")\n",
    "\n",
    "# Verifica√ß√£o importante: n√∫mero de amostras deve coincidir!\n",
    "assert X.shape[0] == y.shape[0], \"ERRO: N√∫mero de amostras em X e y n√£o coincide!\"\n",
    "print(\"‚úÖ Estrutura dos dados est√° correta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Explora√ß√£o Opcional: Valores dos Dados\n",
    "\n",
    "Executa a c√©lula abaixo se quiser ver os **valores reais** das coordenadas. Isso ajuda a entender como os dados est√£o distribu√≠dos numericamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRJ2neKanUwP",
    "outputId": "e5a3223c-8965-4b36-9940-aa9264c43d64"
   },
   "outputs": [],
   "source": [
    "# Visualizar os primeiros 10 pontos e estat√≠sticas b√°sicas\n",
    "print(\"Primeiros 10 pontos (amostras):\")\n",
    "print(X[:10])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Estat√≠sticas descritivas:\")\n",
    "print(f\"M√©dia das caracter√≠sticas: {X.mean(axis=0)}\")\n",
    "print(f\"Desvio padr√£o: {X.std(axis=0)}\")\n",
    "print(f\"Valor m√≠nimo: {X.min(axis=0)}\")\n",
    "print(f\"Valor m√°ximo: {X.max(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üè∑Ô∏è Explorando as Labels (Classes)\n",
    "\n",
    "Agora vamos ver as **classes** (labels) de cada ponto. Em problemas de classifica√ß√£o, estas s√£o as respostas que queremos prever.\n",
    "\n",
    "> **Key Insight:** Em machine learning supervisionado, temos acesso √†s labels durante o treino, mas o modelo deve aprender a prever labels para novos dados que nunca viu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64oT1yBOnWG4",
    "outputId": "24c5c855-a12a-4218-aa61-cea8defb5da5"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPLORA√á√ÉO DAS LABELS (CLASSES)\n",
    "# ============================================================================\n",
    "# y cont√©m as classes verdadeiras para cada amostra\n",
    "print(\"Primeiras 15 labels:\")\n",
    "print(y[:15])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Distribui√ß√£o das classes:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Classe {cls}: {count} amostras ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal de classes √∫nicas: {len(unique)}\")\n",
    "print(f\"Classes: {unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A biblioteca sklearn oferece uma fun√ß√£o que divide o dataset em treino e teste. Temos de importar\n",
    "from sklearn.model_selection import train_test_split\n",
    "# A fun√ß√£o permite-nos escolher a por√ß√£o de teste que queremos \n",
    "# Tipicamente a por√ß√£o de teste √© bastante menor que a de treino, pois precisamos mais dados para treinar. \n",
    "# Propor√ß√µes t√≠picas s√£o 80%/75% de treino e 20%/25% de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Explora√ß√£o Interativa\n",
    "\n",
    "Agora vamos experimentar com diferentes valores de K para ver como isso afeta a performance do modelo!\n",
    "\n",
    "> **üí° Experimenta:** Altera o valor de `n_neighbors` abaixo e observe como a m√©trica **accuracy** muda. Valores maiores de K tendem a ser mais est√°veis mas podem perder detalhes locais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTANDO DIFERENTES VALORES DE K\n",
    "# ============================================================================\n",
    "# @title Experimente diferentes valores de K\n",
    "n_neighbors = 3  # @param {type:\"slider\", min:1, max:15, step:1}\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Treinar modelo com K escolhido\n",
    "knn_exp = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn_exp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar\n",
    "y_pred_train_exp = knn_exp.predict(X_train)\n",
    "y_pred_test_exp = knn_exp.predict(X_test)\n",
    "\n",
    "acc_train_exp = accuracy_score(y_train, y_pred_train_exp)\n",
    "acc_test_exp = accuracy_score(y_test, y_pred_test_exp)\n",
    "\n",
    "print(f\"K = {n_neighbors}\")\n",
    "print(f\"Accuracy no Treino:  {acc_train_exp:.3f} ({acc_train_exp*100:.1f}%)\")\n",
    "print(f\"Accuracy no Teste:   {acc_test_exp:.3f} ({acc_test_exp*100:.1f}%)\")\n",
    "print(f\"Diferen√ßa:           {acc_train_exp - acc_test_exp:.3f}\")\n",
    "\n",
    "# Visualiza√ß√£o da fronteira de decis√£o (opcional, apenas para visualiza√ß√£o 2D)\n",
    "if X.shape[1] == 2:\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    import numpy as np\n",
    "    \n",
    "    h = 0.02  # passo da malha\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = knn_exp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=100, \n",
    "                edgecolors='black', linewidth=1.5, cmap=plt.cm.RdYlBu, label='Treino')\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=100, marker='^',\n",
    "                edgecolors='black', linewidth=1.5, cmap=plt.cm.RdYlBu, label='Teste')\n",
    "    plt.xlabel('Caracter√≠stica 1', fontsize=12)\n",
    "    plt.ylabel('Caracter√≠stica 2', fontsize=12)\n",
    "    plt.title(f'Fronteira de Decis√£o - KNN com K={n_neighbors}', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Observe como a fronteira de decis√£o muda com diferentes valores de K!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Treino e Avalia√ß√£o do Modelo KNN\n",
    "\n",
    "### üéì Conceito: Divis√£o Treino/Teste\n",
    "\n",
    "**Porque devemos dividir os dados?**\n",
    "\n",
    "Em machine learning, nunca avaliamos o modelo com os mesmos dados utilizados para treinar o modelo. Isso seria como fazer um exame com as mesmas perguntas que estudaste!\n",
    "\n",
    "- **Conjunto de Treino (75%)**: Dados usados para \"ensinar\" o modelo\n",
    "- **Conjunto de Teste (25%)**: Dados usados para avaliar se o modelo generaliza bem\n",
    "\n",
    "> **Key Insight:** A divis√£o treino/teste simula a situa√ß√£o real: o modelo aprende com dados hist√≥ricos e deve prever corretamente dados novos que nunca viu.\n",
    "\n",
    "### üéì Conceito: K-Nearest Neighbors (KNN)\n",
    "\n",
    "**Como funciona o KNN?**\n",
    "\n",
    "1. Para classificar um novo ponto, o algoritmo encontra os **K pontos mais pr√≥ximos** no conjunto de treino\n",
    "2. A classe do novo ponto √© determinada pela **vota√ß√£o** das classes dos K vizinhos mais pr√≥ximos\n",
    "3. Com `n_neighbors=1`, usamos apenas o vizinho mais pr√≥ximo (mais simples, mas pode ser inst√°vel)\n",
    "\n",
    "### üìä M√©tricas de Avalia√ß√£o\n",
    "\n",
    "Vamos usar tr√™s ferramentas para avaliar o modelo:\n",
    "\n",
    "1. **Matriz de Confus√£o**: Permite visualisar as previs√µes corretas e erradas por classe\n",
    "2. **Classification Report**: Resume a precision, o recall, o f1-score e a accuracy\n",
    "\n",
    "### ü§î Antes de executar, pensa:\n",
    "\n",
    "- Qual a accuracy que esperas? (Lembra-te: temos 2 classes bem separadas)\n",
    "- O que significa o precision e o recall?\n",
    "- Porque precisamos da matriz de confus√£o?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "nd-0NmwFlQdF",
    "outputId": "542a3d87-72ee-47ba-f765-fa5247e5683c"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTA√á√ïES NECESS√ÅRIAS\n",
    "# ============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# ============================================================================\n",
    "# DIVIS√ÉO TREINO/TESTE\n",
    "# ============================================================================\n",
    "# train_test_split: Divide os dados aleatoriamente em dois conjuntos\n",
    "# Par√¢metros importantes:\n",
    "#   - test_size=0.25: 25% dos dados v√£o para teste (75% para treino)\n",
    "#   - random_state: Garante que a divis√£o √© reproduz√≠vel\n",
    "#   - shuffle=True (padr√£o): Embaralha os dados antes de dividir\n",
    "#\n",
    "# ‚ö†Ô∏è ATEN√á√ÉO: random_state garante resultados reproduz√≠veis. \n",
    "#    Sem ele, cada execu√ß√£o pode dar resultados diferentes!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.25, \n",
    "    random_state=42,  # Adicionado para reproducibilidade\n",
    "    stratify=y  # Mant√©m propor√ß√£o de classes em treino e teste\n",
    ")\n",
    "\n",
    "print(\"Divis√£o dos dados:\")\n",
    "print(f\"  Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Teste:  {X_test.shape[0]} amostras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# TREINO DO MODELO KNN\n",
    "# ============================================================================\n",
    "# KNeighborsClassifier: Algoritmo de classifica√ß√£o baseado em dist√¢ncias\n",
    "# Par√¢metro chave:\n",
    "#   - n_neighbors=1: Usa apenas o vizinho mais pr√≥ximo\n",
    "#     (K=1 √© simples mas pode ser muito sens√≠vel a ru√≠do)\n",
    "#\n",
    "# ‚ö†Ô∏è ATEN√á√ÉO: K=1 significa que cada ponto √© classificado exatamente\n",
    "#    como seu vizinho mais pr√≥ximo. Isso pode levar a overfitting!\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# .fit(): Treina o modelo com os dados de treino\n",
    "#   - X_train: caracter√≠sticas (features)\n",
    "#   - y_train: labels verdadeiras (ground truth)\n",
    "#   O modelo \"aprende\" a rela√ß√£o entre X e y\n",
    "print(\"Treinando modelo KNN (K=1)...\")\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"‚úÖ Modelo treinado!\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREVIS√ïES NO CONJUNTO DE TESTE\n",
    "# ============================================================================\n",
    "# .predict(): Faz previs√µes para novos dados\n",
    "#   - X_test: caracter√≠sticas do conjunto de teste\n",
    "#   - Retorna: y_pred (previs√µes do modelo)\n",
    "#   ‚ö†Ô∏è IMPORTANTE: O modelo N√ÉO v√™ y_test durante a previs√£o!\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(f\"Previs√µes realizadas: {len(y_pred)} amostras\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# AVALIA√á√ÉO DO MODELO: MATRIZ DE CONFUS√ÉO\n",
    "# ============================================================================\n",
    "# Matriz de Confus√£o: Tabela que mostra acertos e erros\n",
    "#   - Diagonal principal: previs√µes corretas\n",
    "#   - Fora da diagonal: erros de classifica√ß√£o\n",
    "#   - √ötil para entender QUAIS classes s√£o confundidas\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Matriz de Confus√£o - Conjunto de Teste', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# AVALIA√á√ÉO DO MODELO: RELAT√ìRIO DE CLASSIFICA√á√ÉO\n",
    "# ============================================================================\n",
    "# Classification Report: Resumo de m√©tricas importantes\n",
    "#   - Precision: Dos que previ como classe X, quantos eram realmente X?\n",
    "#   - Recall: De todos os que s√£o classe X, quantos consegui identificar?\n",
    "#   - F1-score: M√©dia harm√¥nica de precision e recall\n",
    "#   - Support: N√∫mero de amostras de cada classe no teste\n",
    "print(\"=\"*60)\n",
    "print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO - Conjunto de Teste\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1']))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Checkpoint: Comparando Performance em Treino vs. Teste\n",
    "\n",
    "Agora vamos avaliar o modelo no **conjunto de treino** (os dados que ele j√° viu). Isso √© crucial para detectar **overfitting**!\n",
    "\n",
    "> **Key Insight:** Overfitting ocorre quando o modelo \"decora\" os dados de treino mas n√£o generaliza bem para novos dados. Um sinal cl√°ssico √© accuracy muito alta no treino mas baixa no teste.\n",
    "\n",
    "### ü§î Antes de executar, pensa:\n",
    "\n",
    "- Esperas que a accuracy no treino seja maior, menor ou igual √† do teste? Por qu√™?\n",
    "- Se a accuracy no treino for 100% mas no teste for 70%, o que isso indica?\n",
    "- Com K=1, o que esperas ver no conjunto de treino?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "ePb7dbJJt3eN",
    "outputId": "c53831e7-dd9b-4364-bb89-a6cabb3b27bb"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AVALIA√á√ÉO NO CONJUNTO DE TREINO\n",
    "# ============================================================================\n",
    "# ‚ö†Ô∏è ATEN√á√ÉO: Esta avalia√ß√£o √© apenas para compara√ß√£o educacional!\n",
    "#    Em projetos reais, focamos na performance no conjunto de teste.\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "# Matriz de confus√£o no treino\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=[0, 1])\n",
    "disp_train.plot(cmap='Greens', values_format='d')\n",
    "plt.title('Matriz de Confus√£o - Conjunto de Treino', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o no treino\n",
    "print(\"=\"*60)\n",
    "print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO - Conjunto de Treino\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_train, y_pred_train, target_names=['Classe 0', 'Classe 1']))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARA√á√ÉO: TREINO vs. TESTE\n",
    "# ============================================================================\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARA√á√ÉO DE PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy no Treino:  {acc_train:.3f} ({acc_train*100:.1f}%)\")\n",
    "print(f\"Accuracy no Teste:   {acc_test:.3f} ({acc_test*100:.1f}%)\")\n",
    "print(f\"Diferen√ßa:           {acc_train - acc_test:.3f} ({abs(acc_train - acc_test)*100:.1f} pontos percentuais)\")\n",
    "\n",
    "if acc_train > acc_test + 0.1:  # Diferen√ßa maior que 10%\n",
    "    print(\"\\n‚ö†Ô∏è  ATEN√á√ÉO: Grande diferen√ßa detectada!\")\n",
    "    print(\"   Isso pode indicar overfitting - o modelo 'decorou' os dados de treino.\")\n",
    "    print(\"   Solu√ß√µes poss√≠veis: aumentar o K, usar mais dados, ou regulariza√ß√£o.\")\n",
    "elif abs(acc_train - acc_test) < 0.05:\n",
    "    print(\"\\n‚úÖ Performance similar em treino e teste.\")\n",
    "    print(\"   O modelo parece estar generalizando bem!\")\n",
    "else:\n",
    "    print(\"\\nüìä Diferen√ßa moderada entre treino e teste.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymE_JCzzuv1z"
   },
   "source": [
    "---\n",
    "\n",
    "# <a name=\"regress√£o\"></a> üìà Problema de Regress√£o\n",
    "\n",
    "## Introdu√ß√£o: Classifica√ß√£o vs. Regress√£o\n",
    "\n",
    "At√© agora trabalhamos com **classifica√ß√£o** (prever classes discretas: 0 ou 1). Agora vamos trabalhar com a **regress√£o** (prever valores num√©ricos cont√≠nuos).\n",
    "\n",
    "### üéì Diferen√ßas Principais:\n",
    "\n",
    "| Aspecto | Classifica√ß√£o | Regress√£o |\n",
    "|---------|--------------|-----------|\n",
    "| **Output** | Classes discretas (0, 1, 2...) | Valores cont√≠nuos (1.5, 3.7, 10.2...) |\n",
    "| **Exemplo** | \"√â um gato ou c√£o?\" | \"Qual o pre√ßo desta casa?\" |\n",
    "| **M√©tricas** | Accuracy, Precision, Recall | MAE, RMSE, R¬≤ |\n",
    "| **Algoritmos** | KNN, √Årvores de Decis√£o | Regress√£o Linear, Random Forest |\n",
    "\n",
    "### üìä Dataset: Abalone\n",
    "\n",
    "Vamos utilizar o dataset **Abalone** (b√∫zios), que cont√©m caracter√≠sticas f√≠sicas de moluscos e o objetivo √© prever o n√∫mero de an√©is (relacionado com a idade).\n",
    "\n",
    "> **Key Insight:** Em regress√£o, n√£o classificamos em categorias, mas estimamos um valor num√©rico. A avalia√ß√£o mede o \"erro\" entre valores previstos e reais.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 1: Carregamento e Explora√ß√£o de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÅ Passo 1: Carregar o Dataset\n",
    "\n",
    "**Instru√ß√µes:**\n",
    "1. Executa a c√©lula abaixo\n",
    "2. Seleciona \"Choose Files\" ou \"Escolher Ficheiros\"\n",
    "3. Selecione o ficheiro `abalone.csv` do seu computador\n",
    "4. Aguarda a confirma√ß√£o do upload\n",
    "\n",
    "> **üí° Dica:** Se o ficheiro j√° estiver no Colab, podes comentar o c√≥digo de upload e usar `pd.read_csv('abalone.csv')` diretamente.\n",
    "\n",
    "### ‚ö†Ô∏è Importante:\n",
    "- Sem este passo, as c√©lulas seguintes n√£o funcionar√£o\n",
    "- O ficheiro ser√° salvo temporariamente no ambiente do Colab\n",
    "- Se desconectares a sess√£o, precisar√°s de fazer upload novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "b2ERZ5WWu14E",
    "outputId": "5f336616-9082-4658-d020-8e70056b869c"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CARREGAMENTO DE FICHEIRO NO GOOGLE COLAB\n",
    "# ============================================================================\n",
    "# files.upload(): Abre uma interface para selecionar ficheiro do computador\n",
    "#   - Funciona apenas no Google Colab\n",
    "#   - Para Jupyter local, use: df = pd.read_csv('caminho/para/abalone.csv')\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üìÅ Por favor, selecione o ficheiro 'abalone.csv'\")\n",
    "print(\"   (Se j√° estiver no Colab, pode comentar esta c√©lula e usar pd.read_csv diretamente)\\n\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verificar se o upload foi bem-sucedido\n",
    "if 'abalone.csv' in uploaded:\n",
    "    print(f\"‚úÖ Ficheiro carregado com sucesso! Tamanho: {len(uploaded['abalone.csv'])} bytes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Ficheiro 'abalone.csv' n√£o encontrado. Verifique o nome do ficheiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Passo 2: Ler o Dataset para um DataFrame\n",
    "\n",
    "Agora vamos converter o ficheiro carregado em um **DataFrame do pandas**, que √© a estrutura de dados mais comum para trabalhar com dados tabulares em Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HA7hNcJYDRx"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTA√á√ïES E LEITURA DO DATASET\n",
    "# ============================================================================\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pd.read_csv(): L√™ ficheiro CSV e cria um DataFrame\n",
    "#   - io.BytesIO(): Converte os bytes do upload em um objeto que o pandas pode ler\n",
    "#   - DataFrame: Estrutura tabular (como uma planilha Excel) com linhas e colunas\n",
    "df = pd.read_csv(io.BytesIO(uploaded['abalone.csv']))\n",
    "\n",
    "print(\"‚úÖ Dataset carregado com sucesso!\")\n",
    "print(f\"\\nPrimeiras linhas do dataset:\")\n",
    "print(df.head())\n",
    "print(f\"\\nüìä Informa√ß√£o geral:\")\n",
    "print(f\"   Dimens√µes: {df.shape[0]} linhas √ó {df.shape[1]} colunas\")\n",
    "print(f\"   Nome das colunas: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Checkpoint: Explorando a Estrutura do Dataset\n",
    "\n",
    "Antes de processar os dados, pensa:\n",
    "- **Tamanho**: Quantas amostras e features temos?\n",
    "- **Tipos de dados**: Quais s√£o as features num√©ricas? Quais s√£o as categ√≥ricas?\n",
    "- **Valores ausentes**: Temos dados em falta?\n",
    "\n",
    "> **Key Insight:** A explora√ß√£o inicial (EDA - Exploratory Data Analysis) √© crucial. Ela permite revelar problemas que precisam ser resolvidos antes de treinar modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWgnraweZBXm",
    "outputId": "33ca4f35-d1bb-44bc-abd3-ed8f1eff3f56"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIMENS√ïES DO DATASET\n",
    "# ============================================================================\n",
    "print(\"Dimens√µes do dataset:\")\n",
    "print(f\"  (linhas, colunas) = {df.shape}\")\n",
    "print(f\"  ‚Üí {df.shape[0]} amostras\")\n",
    "print(f\"  ‚Üí {df.shape[1]} caracter√≠sticas\\n\")\n",
    "\n",
    "# Verificar valores ausentes\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è  Valores ausentes encontrados:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚úÖ Nenhum valor ausente encontrado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggUr0CPpwLx6",
    "outputId": "fce624aa-7454-4289-c29b-e7ba3fd9078e"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TIPOS DE DADOS\n",
    "# ============================================================================\n",
    "print(\"Tipos de dados por coluna:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Separar vari√°veis num√©ricas e categ√≥ricas\n",
    "numerics = ['float64', 'int64']\n",
    "num_vars = df.select_dtypes(include=numerics).columns.tolist()\n",
    "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"\\nVari√°veis num√©ricas ({len(num_vars)}):\")\n",
    "for var in num_vars:\n",
    "    print(f\"  - {var} ({df[var].dtype})\")\n",
    "\n",
    "if cat_vars:\n",
    "    print(f\"\\nVari√°veis categ√≥ricas ({len(cat_vars)}):\")\n",
    "    for var in cat_vars:\n",
    "        print(f\"  - {var} ({df[var].dtype})\")\n",
    "        print(f\"    Valores √∫nicos: {df[var].nunique()} ‚Üí {df[var].unique()[:5].tolist()}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nenhuma vari√°vel categ√≥rica encontrada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Pr√©-processamento dos Dados\n",
    "\n",
    "### üéì Conceito: Por que Pr√©-processar?\n",
    "\n",
    "Dados brutos raramente est√£o prontos para machine learning. Precisamos:\n",
    "\n",
    "1. **Normalizar vari√°veis num√©ricas**: Colocar todas na mesma escala (ex: 0-1 ou m√©dia=0, desvio=1)\n",
    "   - **Porqu√™?** Algoritmos baseados em dist√¢ncias (como KNN) s√£o sens√≠veis √† escala\n",
    "   - **Exemplo**: Se uma vari√°vel est√° em metros (0-10) e outra em gramas (0-1000), a segunda dominar√° os c√°lculos\n",
    "\n",
    "2. **One-Hot Encoding de vari√°veis categ√≥ricas**: Converter categorias em n√∫meros bin√°rios\n",
    "   - **Porqu√™?** Algoritmos matem√°ticos n√£o entendem texto (\"M\", \"F\", \"I\")\n",
    "   - **Como?** Cada categoria vira uma coluna bin√°ria (0 ou 1)\n",
    "\n",
    "> **Key Insight:** Pr√©-processamento √© t√£o importante quanto escolher o algoritmo certo. Garbage in garbage out, independente do algoritmo.\n",
    "\n",
    "### ü§î Antes de executar, pensa:\n",
    "\n",
    "- Porque n√£o podemos utilizar features categ√≥ricas diretamente?\n",
    "- O que acontece se n√£o normalizarmos as features com escalas muito diferentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEEK2XoRwblz"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTA√á√ïES PARA PR√â-PROCESSAMENTO\n",
    "# ============================================================================\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# ============================================================================\n",
    "# IDENTIFICA√á√ÉO DE VARI√ÅVEIS\n",
    "# ============================================================================\n",
    "# Separar vari√°veis num√©ricas e categ√≥ricas\n",
    "#   - 'Rings' √© a vari√°vel target (o que queremos prever), ent√£o a exclu√≠mos\n",
    "numerics = ['float64', 'int64']\n",
    "num_vars = df.select_dtypes(include=numerics).columns.difference(['Rings'])\n",
    "cat_vars = df.select_dtypes(include='object').columns\n",
    "\n",
    "print(\"Vari√°veis identificadas:\")\n",
    "print(f\"  Num√©ricas: {list(num_vars)}\")\n",
    "print(f\"  Categ√≥ricas: {list(cat_vars)}\")\n",
    "print(f\"  Target: Rings\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# NORMALIZA√á√ÉO DE VARI√ÅVEIS NUM√âRICAS\n",
    "# ============================================================================\n",
    "# StandardScaler: Normaliza para m√©dia=0 e desvio padr√£o=1\n",
    "#   - fit_transform(): Calcula m√©dia/desvio dos dados de treino E aplica transforma√ß√£o\n",
    "#   - Por que normalizar? Vari√°veis com escalas diferentes podem dominar o modelo\n",
    "#\n",
    "# ‚ö†Ô∏è ATEN√á√ÉO: Em projetos reais, voc√™ deve:\n",
    "#   1. fit() apenas nos dados de treino\n",
    "#   2. transform() nos dados de treino E teste\n",
    "#   3. Nunca fit() nos dados de teste! (data leakage)\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[num_vars])\n",
    "\n",
    "print(\"Normaliza√ß√£o aplicada √†s vari√°veis num√©ricas:\")\n",
    "print(f\"  Forma: {X_num.shape}\")\n",
    "print(f\"  M√©dia (deve ser ~0): {X_num.mean(axis=0)[:3]}...\")  # Primeiras 3\n",
    "print(f\"  Desvio padr√£o (deve ser ~1): {X_num.std(axis=0)[:3]}...\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# ONE-HOT ENCODING DE VARI√ÅVEIS CATEG√ìRICAS\n",
    "# ============================================================================\n",
    "# OneHotEncoder: Converte categorias em colunas bin√°rias\n",
    "#   Exemplo: Sexo ['M', 'F', 'I'] ‚Üí 3 colunas: [1,0,0], [0,1,0], [0,0,1]\n",
    "#   - sparse_output=False: Retorna array numpy denso (n√£o esparso)\n",
    "#\n",
    "# ‚ö†Ô∏è ATEN√á√ÉO: One-hot encoding aumenta o n√∫mero de colunas!\n",
    "#    Se tiver 1 vari√°vel categ√≥rica com 3 valores ‚Üí 3 colunas\n",
    "enc = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' evita multicolinearidade\n",
    "X_cat = enc.fit_transform(df[cat_vars])\n",
    "\n",
    "print(\"One-hot encoding aplicado √†s vari√°veis categ√≥ricas:\")\n",
    "print(f\"  Forma: {X_cat.shape}\")\n",
    "print(f\"  Categorias originais: {list(cat_vars)}\")\n",
    "if len(cat_vars) > 0:\n",
    "    print(f\"  Nomes das novas colunas: {enc.get_feature_names_out(cat_vars.tolist())}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONCATENA√á√ÉO: JUNTAR VARI√ÅVEIS NUM√âRICAS E CATEG√ìRICAS PROCESSADAS\n",
    "# ============================================================================\n",
    "# np.concatenate(): Junta arrays ao longo do eixo especificado\n",
    "#   - axis=1: Concatena colunas (horizontalmente)\n",
    "#   - axis=0: Concatena linhas (verticalmente)\n",
    "X_processed = np.concatenate([X_num, X_cat], axis=1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PR√â-PROCESSAMENTO CONCLU√çDO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Forma final de X_processed: {X_processed.shape}\")\n",
    "print(f\"  ‚Üí {X_processed.shape[0]} amostras\")\n",
    "print(f\"  ‚Üí {X_processed.shape[1]} caracter√≠sticas (ap√≥s processamento)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Verifica√ß√£o: Dimens√µes Ap√≥s Pr√©-processamento\n",
    "\n",
    "Executa a c√©lula abaixo para confirmar que o pr√©-processamento foi aplicado corretamente. Denota como o n√∫mero de colunas aumentou devido ao one-hot encoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Y9qmROVY8yr",
    "outputId": "e556cbd8-713f-4af9-9937-696b2f3f35ff"
   },
   "outputs": [],
   "source": [
    "# Verifica√ß√£o final da estrutura\n",
    "print(\"Estrutura dos dados processados:\")\n",
    "print(f\"  X_processed.shape = {X_processed.shape}\")\n",
    "print(f\"\\nCompara√ß√£o:\")\n",
    "print(f\"  Colunas originais (num√©ricas): {len(num_vars)}\")\n",
    "print(f\"  Colunas ap√≥s one-hot: {X_cat.shape[1] if len(cat_vars) > 0 else 0}\")\n",
    "print(f\"  Total de colunas processadas: {X_processed.shape[1]}\")\n",
    "print(f\"\\n‚úÖ Dados prontos para treino do modelo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Treino e Avalia√ß√£o do Modelo\n",
    "\n",
    "### üìä Divis√£o Treino/Teste\n",
    "\n",
    "Agora vamos dividir os dados processados em conjuntos de treino e teste, assim como fizemos no problema de classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2lRwwtZyg8d"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIVIS√ÉO TREINO/TESTE\n",
    "# ============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir dados processados e target\n",
    "#   - X_processed: caracter√≠sticas j√° normalizadas e codificadas\n",
    "#   - df['Rings']: vari√°vel target (n√∫mero de an√©is = idade)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, \n",
    "    df['Rings'], \n",
    "    test_size=0.25,\n",
    "    random_state=42  # Reproducibilidade\n",
    ")\n",
    "\n",
    "print(\"Divis√£o dos dados:\")\n",
    "print(f\"  Treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"  Teste:  {X_test.shape[0]} amostras\")\n",
    "print(f\"\\nEstat√≠sticas do target (Rings):\")\n",
    "print(f\"  Treino - M√©dia: {y_train.mean():.2f}, Desvio: {y_train.std():.2f}\")\n",
    "print(f\"  Teste  - M√©dia: {y_test.mean():.2f}, Desvio: {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Conceito: Regress√£o Linear\n",
    "\n",
    "**O que √© Regress√£o Linear?**\n",
    "\n",
    "√â um algoritmo que encontra a \"melhor linha\" (ou hiperplano em m√∫ltiplas dimens√µes) que relaciona as caracter√≠sticas (X) com o target (y).\n",
    "\n",
    "- **F√≥rmula simples**: `y = a*x + b` (onde `a` √© o coeficiente e `b` √© o intercepto). No secund√°rio esta f√≥rmula √© conhecida como a equa√ß√£o da reta.\n",
    "- **Objetivo**: Minimizar o erro entre valores previstos e reais\n",
    "- **Vantagens**: Simples, interpret√°vel, r√°pido\n",
    "- **Limita√ß√µes**: Assume rela√ß√£o linear (pode n√£o capturar padr√µes complexos)\n",
    "\n",
    "### üìä M√©tricas de Regress√£o\n",
    "\n",
    "Diferente de classifica√ß√£o, em regress√£o medimos **erro**:\n",
    "\n",
    "- **MAE (Mean Absolute Error)**: Erro m√©dio absoluto\n",
    "  - Exemplo: Se prevermos 10 e o valor real √© 12, o erro √© |12-10| = 2\n",
    "  - Interpreta√ß√£o: \"Em m√©dia, erramos X unidades\"\n",
    "\n",
    "> **Key Insight:** Na regress√£o, queremos minimizar o erro. Quanto menor o MAE, melhor o modelo.\n",
    "\n",
    "### ü§î Antes de executar, pensa:\n",
    "\n",
    "- O que significa um MAE de 1.5 no contexto deste problema?\n",
    "- Porque n√£o utilizamos a accuracy na regress√£o?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJ2mFNr6yqyV",
    "outputId": "2bbdf557-418e-483e-c347-066644b43344"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TREINO DO MODELO DE REGRESS√ÉO LINEAR\n",
    "# ============================================================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# LinearRegression: Algoritmo de regress√£o linear\n",
    "#   - Encontra os coeficientes que minimizam o erro quadr√°tico\n",
    "#   - N√£o precisa de hiperpar√¢metros (diferente de KNN)\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Treinar o modelo\n",
    "print(\"Treinando modelo de Regress√£o Linear...\")\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"‚úÖ Modelo treinado!\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREVIS√ïES NO CONJUNTO DE TESTE\n",
    "# ============================================================================\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(f\"Previs√µes realizadas: {len(y_pred)} amostras\")\n",
    "print(f\"Exemplo de previs√µes (primeiras 5):\")\n",
    "for i in range(min(5, len(y_pred))):\n",
    "    print(f\"  Real: {y_test.iloc[i]:.2f}, Previsto: {y_pred[i]:.2f}, Erro: {abs(y_test.iloc[i] - y_pred[i]):.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# AVALIA√á√ÉO DO MODELO: M√âTRICAS DE REGRESS√ÉO\n",
    "# ============================================================================\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"M√âTRICAS DE AVALIA√á√ÉO - Conjunto de Teste\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE  (Mean Absolute Error):  {mae:.3f}\")\n",
    "print(f\"     ‚Üí Em m√©dia, erramos {mae:.2f} an√©is por previs√£o\")\n",
    "print(f\"\\nRMSE (Root Mean Squared Error): {rmse:.3f}\")\n",
    "print(f\"     ‚Üí Penaliza mais erros grandes\")\n",
    "print(f\"\\nR¬≤   (Coefficient of Determination): {r2:.3f}\")\n",
    "print(f\"     ‚Üí {r2*100:.1f}% da vari√¢ncia √© explicada pelo modelo\")\n",
    "print(f\"     ‚Üí Quanto mais pr√≥ximo de 1, melhor (m√°ximo = 1.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZA√á√ÉO: VALORES REAIS vs. PREVISTOS\n",
    "# ============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gr√°fico de dispers√£o: valores reais vs. previstos\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, s=50)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Previs√£o Perfeita')\n",
    "plt.xlabel('Valores Reais (Rings)', fontsize=12)\n",
    "plt.ylabel('Valores Previstos (Rings)', fontsize=12)\n",
    "plt.title('Valores Reais vs. Previstos - Regress√£o Linear', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpreta√ß√£o do gr√°fico:\n",
    "#   - Pontos pr√≥ximos da linha vermelha = boas previs√µes\n",
    "#   - Pontos distantes = erros maiores\n",
    "#   - Padr√µes sistem√°ticos (curva) = modelo pode estar subajustado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Resumo e Reflex√£o\n",
    "\n",
    "### ‚úÖ O que aprendemos hoje:\n",
    "\n",
    "1. **Classifica√ß√£o vs. Regress√£o**\n",
    "   - Classifica√ß√£o: prever classes (0/1)\n",
    "   - Regress√£o: prever valores num√©ricos cont√≠nuos\n",
    "\n",
    "2. **Pipeline Completo de ML**\n",
    "   - Carregamento dos dados ‚Üí Explora√ß√£o ‚Üí Pr√©-processamento ‚Üí Treino ‚Üí Avalia√ß√£o\n",
    "\n",
    "3. **Pr√©-processamento Essencial**\n",
    "   - Normaliza√ß√£o de vari√°veis num√©ricas\n",
    "   - One-hot encoding de vari√°veis categ√≥ricas\n",
    "\n",
    "4. **Avalia√ß√£o de Modelos**\n",
    "   - Classifica√ß√£o: Matriz de confus√£o, Precision, Recall, F1-score\n",
    "   - Regress√£o: MAE, RMSE, R¬≤\n",
    "\n",
    "5. **Overfitting**\n",
    "   - Diferen√ßa entre performance em treino vs. teste\n",
    "   - Import√¢ncia de avaliar nos dados de teste\n",
    "\n",
    "### ü§î Perguntas para Reflex√£o:\n",
    "\n",
    "1. Porque dividimos os dados em treino e teste?\n",
    "2. Qual a diferen√ßa entre normaliza√ß√£o e one-hot encoding?\n",
    "3. O que indica um modelo com alta accuracy no treino mas baixa no teste?\n",
    "4. Em regress√£o, porque utilizamos o MAE inv√©s do accuracy?\n",
    "\n",
    "### üìö Pr√≥ximos Passos:\n",
    "\n",
    "Agora est√°s pronto para praticar! Vai para o notebook de **Exerc√≠cios** e aplica os conceitos que acabaste de aprender.\n",
    "\n",
    "---\n",
    "\n",
    "> **üíæ Lembra-te:** N√£o se aprende a tocar piano a olhar para um pianista! Praticar √© a melhor forma de absorver novo conhecimento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
