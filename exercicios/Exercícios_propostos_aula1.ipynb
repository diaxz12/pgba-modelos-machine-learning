{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr0D2rel2Gp8"
   },
   "source": [
    "# ‚úèÔ∏è EXERC√çCIOS: Introdu√ß√£o aos principais conceitos de modelos preditivos.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã √çndice\n",
    "\n",
    "1. [Exerc√≠cio 1: Classifica√ß√£o com Dataset Diabetes](#exercicio1)\n",
    "2. [Exerc√≠cio 2: Regress√£o com Dataset Housing](#exercicio2)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos de Aprendizagem\n",
    "\n",
    "Ao completar estes exerc√≠cios, voc√™ ser√° capaz de:\n",
    "\n",
    "1. **Aplicar** o pipeline completo de ML em problemas reais\n",
    "2. **Identificar** vari√°veis categ√≥ricas e num√©ricas em datasets\n",
    "3. **Implementar** pr√©-processamento (normaliza√ß√£o e one-hot encoding)\n",
    "4. **Treinar e avaliar** modelos de classifica√ß√£o e regress√£o\n",
    "5. **Interpretar** m√©tricas de avalia√ß√£o e diagnosticar problemas\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Pr√©-requisitos\n",
    "\n",
    "Antes de come√ßar, certifique-se de que voc√™:\n",
    "- ‚úÖ Completou o notebook **Walkthrough (Aula1.ipynb)**\n",
    "- ‚úÖ Entende os conceitos de classifica√ß√£o e regress√£o\n",
    "- ‚úÖ Sabe usar pandas para manipula√ß√£o de dados\n",
    "- ‚úÖ Compreende divis√£o treino/teste\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Como Usar Este Notebook\n",
    "\n",
    "1. **Leia cada exerc√≠cio completamente** antes de come√ßar\n",
    "2. **Use as dicas progressivas** se ficar preso (clique para expandir)\n",
    "3. **Valide suas respostas** usando as c√©lulas de verifica√ß√£o\n",
    "4. **Compare com solu√ß√µes** apenas ap√≥s tentar resolver\n",
    "\n",
    "> **üíæ Lembrete:** Salve seu trabalho frequentemente! No Colab: File ‚Üí Save ou Ctrl+S\n",
    "\n",
    "---\n",
    "\n",
    "# <a name=\"exercicio1\"></a> üìä Exerc√≠cio 1: Classifica√ß√£o com Dataset Diabetes\n",
    "\n",
    "## Objetivo do Exerc√≠cio\n",
    "\n",
    "Aplicar o pipeline completo de classifica√ß√£o usando o dataset **Diabetes**, que cont√©m caracter√≠sticas de pacientes e o objetivo √© prever se o paciente tem diabetes (1) ou n√£o (0).\n",
    "\n",
    "### üéØ Objetivos Espec√≠ficos:\n",
    "- Carregar e explorar dados reais\n",
    "- Identificar e processar vari√°veis categ√≥ricas e num√©ricas\n",
    "- Treinar um modelo KNN\n",
    "- Avaliar e interpretar resultados\n",
    "\n",
    "### ‚è±Ô∏è Tempo Estimado: 45-60 minutos\n",
    "\n",
    "### üü¢ N√≠vel: B√°sico a Intermedi√°rio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 0: Configura√ß√£o Inicial\n",
    "\n",
    "Execute as c√©lulas abaixo para configurar o ambiente e carregar as ferramentas necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kc-8_OQFm64"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FUN√á√ÉO DE PR√â-PROCESSAMENTO\n",
    "# ============================================================================\n",
    "# Esta fun√ß√£o ser√° reutilizada em todos os exerc√≠cios\n",
    "# Ela normaliza vari√°veis num√©ricas e aplica one-hot encoding √†s categ√≥ricas\n",
    "\n",
    "def process_data(X, num_vars, cat_vars):\n",
    "    \"\"\"\n",
    "    Processa dados para machine learning: normaliza num√©ricas e codifica categ√≥ricas.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Dataset com vari√°veis independentes\n",
    "    num_vars : list\n",
    "        Lista com nomes das vari√°veis num√©ricas\n",
    "    cat_vars : list\n",
    "        Lista com nomes das vari√°veis categ√≥ricas\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    X_processed : numpy array\n",
    "        Array processado pronto para treino\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    enc = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    \n",
    "    # Processar vari√°veis num√©ricas (normaliza√ß√£o)\n",
    "    if len(num_vars) > 0:\n",
    "        X_num = scaler.fit_transform(X[num_vars])\n",
    "    else:\n",
    "        X_num = np.array([]).reshape(X.shape[0], 0)\n",
    "    \n",
    "    # Processar vari√°veis categ√≥ricas (one-hot encoding)\n",
    "    if len(cat_vars) > 0:\n",
    "        X_cat = enc.fit_transform(X[cat_vars])\n",
    "    else:\n",
    "        X_cat = np.array([]).reshape(X.shape[0], 0)\n",
    "    \n",
    "    # Concatenar resultados\n",
    "    if X_num.shape[1] > 0 and X_cat.shape[1] > 0:\n",
    "        X_processed = np.concatenate([X_num, X_cat], axis=1)\n",
    "    elif X_num.shape[1] > 0:\n",
    "        X_processed = X_num\n",
    "    else:\n",
    "        X_processed = X_cat\n",
    "    \n",
    "    return X_processed\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o process_data() carregada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQTcOgGaHyhH"
   },
   "source": [
    "### Importa√ß√£o de Bibliotecas\n",
    "\n",
    "Execute esta c√©lula para importar todas as bibliotecas necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ98BGrN3OHv"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"‚úÖ Todas as bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP1Vz0tyH3X1"
   },
   "source": [
    "### Carregamento do Dataset\n",
    "\n",
    "Execute a c√©lula abaixo para carregar o dataset **diabetes.csv**. \n",
    "\n",
    "> **üí° Dica:** Se o ficheiro j√° estiver no Colab, comente as linhas de upload e use `df = pd.read_csv('diabetes.csv')` diretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQNGgonJ3UE6"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CARREGAMENTO DO DATASET\n",
    "# ============================================================================\n",
    "# Op√ß√£o 1: Upload do ficheiro (descomente se necess√°rio)\n",
    "uploaded = files.upload()\n",
    "df = pd.read_csv(io.BytesIO(uploaded['diabetes.csv']))\n",
    "\n",
    "# Op√ß√£o 2: Se o ficheiro j√° estiver no Colab, use:\n",
    "# df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Verifica√ß√£o\n",
    "print(\"‚úÖ Dataset carregado!\")\n",
    "print(f\"   Dimens√µes: {df.shape[0]} linhas √ó {df.shape[1]} colunas\")\n",
    "print(f\"   Colunas: {list(df.columns)}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oswRM5bBIA6l"
   },
   "source": [
    "---\n",
    "\n",
    "## üéØ Agora √© sua vez! Resolva os exerc√≠cios abaixo\n",
    "\n",
    "Siga os passos indicados. Se precisar de ajuda, expanda as dicas progressivas em cada se√ß√£o.\n",
    "\n",
    "> **üí° Estrat√©gia:** \n",
    "> 1. Leia a quest√£o completamente\n",
    "> 2. Tente resolver sozinho primeiro\n",
    "> 3. Se ficar preso, use as dicas (comece pela Dica 1)\n",
    "> 4. Valide sua solu√ß√£o com as c√©lulas de verifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXERC√çCIO 1.1: IDENTIFICA√á√ÉO DE VARI√ÅVEIS\n",
    "# ============================================================================\n",
    "# TODO: Complete o c√≥digo abaixo\n",
    "# 1. Identifique vari√°veis num√©ricas (exceto 'Outcome')\n",
    "# 2. Identifique vari√°veis categ√≥ricas (se houver)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "numerics = ['int64', 'float64']\n",
    "num_vars = df.select_dtypes(include=numerics).columns.difference(['Outcome']).tolist()\n",
    "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Verifica√ß√£o autom√°tica\n",
    "print(\"Vari√°veis identificadas:\")\n",
    "print(f\"  Num√©ricas ({len(num_vars)}): {num_vars}\")\n",
    "print(f\"  Categ√≥ricas ({len(cat_vars)}): {cat_vars}\")\n",
    "print(f\"  Target: Outcome\")\n",
    "\n",
    "# Valida√ß√£o\n",
    "assert 'Outcome' not in num_vars, \"‚ùå ERRO: 'Outcome' n√£o deve estar em num_vars!\"\n",
    "assert 'Outcome' not in cat_vars, \"‚ùå ERRO: 'Outcome' n√£o deve estar em cat_vars!\"\n",
    "assert len(num_vars) > 0, \"‚ùå ERRO: Deve haver pelo menos uma vari√°vel num√©rica!\"\n",
    "print(\"\\n‚úÖ Estrutura de vari√°veis correta!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXERC√çCIO 1.2: PR√â-PROCESSAMENTO\n",
    "# ============================================================================\n",
    "# TODO: Complete o c√≥digo abaixo\n",
    "# 1. Separe X (vari√°veis independentes) e y (target)\n",
    "# 2. Use process_data() para processar X\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "X_processed = process_data(X, num_vars, cat_vars)\n",
    "\n",
    "# Verifica√ß√£o\n",
    "print(\"Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"  X.shape: {X.shape}\")\n",
    "print(f\"  y.shape: {y.shape}\")\n",
    "print(f\"  X_processed.shape: {X_processed.shape}\")\n",
    "print(f\"  Tipo de X_processed: {type(X_processed)}\")\n",
    "\n",
    "# Valida√ß√£o\n",
    "assert X_processed.shape[0] == len(df), \"‚ùå ERRO: N√∫mero de linhas n√£o coincide!\"\n",
    "assert isinstance(X_processed, np.ndarray), \"‚ùå ERRO: X_processed deve ser um array numpy!\"\n",
    "assert 'Outcome' not in X.columns, \"‚ùå ERRO: 'Outcome' n√£o deve estar em X!\"\n",
    "print(\"\\n‚úÖ Pr√©-processamento correto!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdFDgqQj2uLU"
   },
   "source": [
    "### üü¢ Exerc√≠cio 1.1: Identifica√ß√£o de Vari√°veis\n",
    "\n",
    "**Objetivo:** Identificar quais vari√°veis s√£o num√©ricas (cont√≠nuas) e quais s√£o categ√≥ricas.\n",
    "\n",
    "**Tarefa:** \n",
    "- Crie listas `num_vars` e `cat_vars` contendo os nomes das vari√°veis num√©ricas e categ√≥ricas, respectivamente\n",
    "- **IMPORTANTE:** A vari√°vel `Outcome` √© o **target** (n√£o deve estar em nenhuma das listas!)\n",
    "\n",
    "**Crit√©rios de Sucesso:**\n",
    "- ‚úÖ `num_vars` cont√©m todas as vari√°veis num√©ricas (exceto Outcome)\n",
    "- ‚úÖ `cat_vars` cont√©m todas as vari√°veis categ√≥ricas (se houver)\n",
    "- ‚úÖ `Outcome` n√£o est√° em nenhuma das listas\n",
    "\n",
    "<details>\n",
    "<summary>üí° Dica 1: Como identificar tipos de dados</summary>\n",
    "\n",
    "Use `df.dtypes` para ver o tipo de cada coluna:\n",
    "- `int64` ou `float64` ‚Üí num√©ricas\n",
    "- `object` ‚Üí geralmente categ√≥ricas (mas verifique!)\n",
    "\n",
    "```python\n",
    "print(df.dtypes)\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üí° Dica 2: Selecionar por tipo</summary>\n",
    "\n",
    "Use `select_dtypes()` para filtrar colunas por tipo:\n",
    "\n",
    "```python\n",
    "# Num√©ricas\n",
    "numerics = ['int64', 'float64']\n",
    "num_vars = df.select_dtypes(include=numerics).columns.tolist()\n",
    "\n",
    "# Categ√≥ricas  \n",
    "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üí° Dica 3: Remover o target</summary>\n",
    "\n",
    "Lembre-se de remover 'Outcome' das listas:\n",
    "\n",
    "```python\n",
    "num_vars = [var for var in num_vars if var != 'Outcome']\n",
    "# ou\n",
    "num_vars = df.select_dtypes(include=numerics).columns.difference(['Outcome']).tolist()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzyYfR9r4f__"
   },
   "source": [
    "1.2 Normalize as vari√°veis cont√≠nuas (se existirem) e processe as vari√°veis categ√≥ricas (se existirem) atrav√©s do one-hot encoding. A vari√°vel `Outcome` √© o target. Dica: chame a fun√ß√£o `process_data` criada acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GfTrZp322P3"
   },
   "source": [
    "1.3 Divida o data set em 80% de treino e 20% de teste usando `train_test_split`. Se ainda n√£o se sentirem confort√°veis, podem executar o c√≥digo fornecido abaixo como exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üéì Checkpoint: Exerc√≠cio 1 Conclu√≠do!\n",
    "\n",
    "**Antes de prosseguir, verifique:**\n",
    "\n",
    "- [ ] Identifiquei corretamente vari√°veis num√©ricas e categ√≥ricas\n",
    "- [ ] Apliquei pr√©-processamento (normaliza√ß√£o e one-hot encoding)\n",
    "- [ ] Dividi os dados em treino (80%) e teste (20%)\n",
    "- [ ] Treinei um modelo KNN e avaliei sua performance\n",
    "- [ ] Entendi a interpreta√ß√£o da matriz de confus√£o e classification report\n",
    "\n",
    "**Perguntas para reflex√£o:**\n",
    "1. Qual a accuracy do seu modelo? √â satisfat√≥ria?\n",
    "2. H√° diferen√ßa significativa entre precision e recall? O que isso indica?\n",
    "3. Se a accuracy fosse muito baixa, quais seriam as poss√≠veis causas?\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Refer√™ncias ao Walkthrough\n",
    "\n",
    "Se precisar revisar conceitos:\n",
    "- **Pr√©-processamento:** Veja se√ß√£o \"Pr√©-processamento dos Dados\" no notebook Walkthrough\n",
    "- **KNN:** Veja se√ß√£o \"Treino e Avalia√ß√£o do Modelo KNN\" no notebook Walkthrough\n",
    "- **M√©tricas:** Veja se√ß√£o \"Avalia√ß√£o do Modelo\" no notebook Walkthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmV2xsPFHQxL"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # Fun√ß√£o da biblioteca sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wObFsjT4-BlS"
   },
   "source": [
    "1.4 Treine o algoritmo KNN para prever os dados de teste e avalie a sua performance (matriz de confus√£o e classification report). Podem usar diretamente o c√≥digo fornecido para se focarem na interpreta√ß√£o dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMPGZUdKe4T5"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3) # Chamar o algoritmo\n",
    "knn.fit(X_train, y_train) # Aqui estamos a dar os dados de treino (X+y) ao modelo para ele treinar; estamos a fazer o fitting\n",
    "y_pred = knn.predict(X_test) # Aqui estamos a testar o algoritmo treinado, dando-lhe apenas as vari√°veis explicativas para ele prever a vari√°vel de output sem a ver\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=df['Outcome'].unique()) # Criar a matriz de condus√£o\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=df['Outcome'].unique()) # Para poder ver a matriz\n",
    "disp.plot() # Fazer o gr√°fico\n",
    "# O classification report mostra as m√©tricas accuracy, precision e recall. Mostra ainda a f1-score que √© uma m√©trica que utiliza o precision e o recall\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar tipos de dados\n",
    "print(\"Tipos de dados:\")\n",
    "print(df2.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Vari√°veis num√©ricas:\")\n",
    "numerics = ['int64', 'float64']\n",
    "num_cols = df2.select_dtypes(include=numerics).columns.tolist()\n",
    "print(f\"  {num_cols}\")\n",
    "print(\"\\nVari√°veis categ√≥ricas:\")\n",
    "cat_cols = df2.select_dtypes(include='object').columns.tolist()\n",
    "print(f\"  {cat_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq3GQa8pfikV"
   },
   "source": [
    "# **2. Exerc√≠cio de regress√£o**\n",
    "\n",
    "Leia o dataset \"housing\" para um DataFrame. O objetivo √© prever o pre√ßo das casas. Cada fun√ß√£o em baixo deve ser completada por voc√™s para praticarem o pipeline completo de regress√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnrQmg1GId02"
   },
   "source": [
    "Corra os pr√≥ximos comandos para carregar o ficheiro `housing.csv` a partir do seu computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGN9HrUJgQGX"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "df2 = pd.read_csv(io.BytesIO(uploaded['housing.csv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtthwKVhVC3w"
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LNDWqK6Iggj"
   },
   "source": [
    "Preencha as fun√ß√µes seguintes para construir o vosso pr√≥prio pipeline de regress√£o. Sigam as notas nos coment√°rios para saber o que fazer em cada uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BHX-IW8ew1o"
   },
   "outputs": [],
   "source": [
    "def process_data(X, num_vars, cat_vars):\n",
    "  # Copiar fun√ß√£o de cima\n",
    "\n",
    "\n",
    "def split_data(X, y, test_portion):\n",
    "  # Fazer\n",
    "\n",
    "def train_model(X_train, X_test, y_train):\n",
    "  reg = LinearRegression().fit(X_train, y_train) # Fazer o fitting aos dados de treino\n",
    "  y_pred = reg.predict(X_test)\n",
    "\n",
    "  return y_pred\n",
    "\n",
    "def get_error(y_pred, y_true):\n",
    "  print(f'Erro absoluto m√©dio = {mean_absolute_error(y_true, y_pred)}')\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(range(0, y_true.shape[0]), y_true, color='blue', label='Valores reais')\n",
    "  plt.plot(range(0, y_pred.shape[0]), y_pred, color='red', label='Valores previstos', linewidth=0.5)\n",
    "  plt.grid()\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete o bloco final identificando o nome da vari√°vel alvo (pre√ßo) e chamando as fun√ß√µes criadas: processem dados, dividam em treino/teste, treinem o modelo e calculem o erro e o R2. A leitura do c√≥digo de exemplo deve servir como guia para a ordem correta das opera√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSNoFopXhxvW"
   },
   "outputs": [],
   "source": [
    "target = XXX # Identificar a vari√°vel a prever\n",
    "independent_vars = df2.columns.difference([target]) # Identificar as vari√°veis explicativas/independentes\n",
    "X, y = df2[independent_vars], df2[target] # Dividir o target das vari√°veis explicativas\n",
    "\n",
    "cat_vars = ['CHAS'] # Identificar as vari√°veis categ√≥ricas\n",
    "num_vars = df2.columns.difference([target] + cat_vars).tolist() # Identificar as vari√°veis num√©ricas, que s√£o todas menos as categ√≥ricas e o target\n",
    "X = process_data(X, num_vars, cat_vars) # Processar os dados, este passo √© comum a todos os algoritmos, logo podemos s√≥ fazer de uma vez\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.3) #Dividir o dataset em treino e teste\n",
    "y_pred = train_model(X_train, X_test, y_train)\n",
    "get_error(y_pred, y_test)\n",
    "print(f'R2 = {r2_score(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
